{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bffeb280",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import ast\n",
    "import validators\n",
    "import string\n",
    "import demoji\n",
    "import pyLDAvis.sklearn\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from nltk import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb592696",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def DFToDocument(df):\n",
    "    document = []\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    for i, row in df.iterrows():\n",
    "        sentence = \"\"\n",
    "        tokenized_text = ast.literal_eval(row['tokenized_text'])\n",
    "        pos_tags = pos_tag(tokenized_text)\n",
    "        tonkenized_text = [token for token, pos in pos_tags if pos not in ['JJ', 'JJR', 'JJS', 'RB', 'RBR', 'RBS', 'VB']]\n",
    "        for token in tokenized_text:\n",
    "            if token not in stop_words and not validators.url(token) and token not in string.punctuation and not re.search(r'(chat[-\\s])?gpt|\\d+', token.lower()):\n",
    "                sentence += lemmatizer.lemmatize(token) + ' '\n",
    "        sentence = demoji.replace(string = sentence, repl = \"\")\n",
    "        document.append(sentence[:-1])\n",
    "    return document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6095fbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ProcessInput(inputArray):\n",
    "    document = []\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    for text in inputArray:\n",
    "        sentence = \"\"\n",
    "        tokenized_text = nltk.word_tokenize(text)\n",
    "        pos_tags = pos_tag(tokenized_text)\n",
    "        tonkenized_text = [token for token, pos in pos_tags if pos not in ['JJ', 'JJR', 'JJS', 'RB', 'RBR', 'RBS', 'VB']]\n",
    "        for token in tokenized_text:\n",
    "            if token not in stop_words and not validators.url(token) and token not in string.punctuation and not re.search(r'(chat[-\\s])?gpt|\\d+', token.lower()):\n",
    "                sentence += lemmatizer.lemmatize(token) + ' '\n",
    "        sentence = demoji.replace(string = sentence, repl = \"\")\n",
    "        document.append(sentence[:-1])\n",
    "    return document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fd1f3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ShowDocInTopic(topic, count, model_output, model):\n",
    "    lda_df = pd.DataFrame({\"text\": document_train, \"topic\": model_output.argmax(axis=1)})\n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "    return lda_df[lda_df['topic'] == topic].head(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5661271",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def display_topics(model, feature_names, no_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic %d:\" % (topic_idx))\n",
    "        print(\" \".join([feature_names[i] for i in topic.argsort()[:-no_top_words - 1:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "215285c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./translated_dataframe.csv')\n",
    "document = DFToDocument(df)\n",
    "document_train, document_test = train_test_split(document, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c9993dd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "train_vecs = vectorizer.fit_transform(document_train)\n",
    "test_vecs = vectorizer.transform(document_test)\n",
    "feature_names = vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b65a9973",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "ai tool via could make code it data business like\n",
      "Topic 1:\n",
      "google better chatbot next company ai point the bard created\n",
      "Topic 2:\n",
      "make take time based research yet fun asked way life\n",
      "Topic 3:\n",
      "want and writing ai create love crypto high correct from\n",
      "Topic 4:\n",
      "think good like used still much know when learning try\n",
      "Topic 5:\n",
      "use chat using many way asked work it great version\n",
      "Topic 6:\n",
      "ai you technology world interesting future new language problem the\n",
      "Topic 7:\n",
      "it answer question ai bing ask time chat like write\n",
      "Topic 8:\n",
      "the information even use one say that student thing is\n",
      "Topic 9:\n",
      "ai openai using service model video new image generative language\n"
     ]
    }
   ],
   "source": [
    "lda = LatentDirichletAllocation(n_components=10, learning_method='online', n_jobs = -1, random_state=1)\n",
    "lda_output = lda.fit_transform(train_vecs)\n",
    "display_topics(lda, feature_names, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d91a160d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity:  9756.231697967969\n"
     ]
    }
   ],
   "source": [
    "print(\"Perplexity: \", lda.perplexity(test_vecs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94a2e641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_params = {'learning_decay': np.arange(0.1, 0.9, 0.1), 'doc_topic_prior': np.arange(0.1, 0.9, 0.1), 'topic_word_prior': np.arange(0.1, 0.9, 0.1)}\n",
    "docs_lda = LatentDirichletAllocation(n_components=6, learning_decay=0.8, topic_word_prior=0.1, learning_method=\"online\", n_jobs=-1)  \n",
    "\n",
    "model = GridSearchCV(docs_lda, param_grid=search_params, n_jobs=8, verbose=3)\n",
    "\n",
    "model.fit(train_vecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89de3e1",
   "metadata": {},
   "source": [
    "learning_decay = 0.8\n",
    "doc_topic_prior = 0.8\n",
    "topic_word_prior = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb01f024",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_lda = LatentDirichletAllocation(n_components=6, learning_method=\"online\", learning_decay= 0.8, doc_topic_prior= 0.8, topic_word_prior= 0.1, n_jobs=-1)\n",
    "best_lda_output = best_lda.fit_transform(train_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65c6b914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "make you say people code it time in what bot love life for is point\n",
      "Topic 1:\n",
      "article good post morning problem chat high generated blog sentence note lol asked link called\n",
      "Topic 2:\n",
      "ai openai new google bing tool technology model microsoft artificialintelligence search how language via text\n",
      "Topic 3:\n",
      "use using asked write chat want day way if one prompt take come help create\n",
      "Topic 4:\n",
      "the intelligence artificial world future human what year nft crypto english language information source become\n",
      "Topic 5:\n",
      "like it answer know question think ask would get much even good thing also really\n"
     ]
    }
   ],
   "source": [
    "display_topics(best_lda, feature_names, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77e8a446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity:  6139.150702191745\n"
     ]
    }
   ],
   "source": [
    "best_lda_df = pd.DataFrame({\"text\": document_train, \"topic\": best_lda_output.argmax(axis=1)})\n",
    "print(\"Perplexity: \", best_lda.perplexity(test_vecs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c6b72e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_doc = vectorizer.transform(ProcessInput(['I hate chatgpt, it is going to take my job']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bab1ecf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_probs = best_lda.transform(new_doc)\n",
    "topic_probs.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2698fd18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'm exploring using get way help #teaching lot task asked #faculty day take needed necessary time teaching researching appropriaterelevant meaningful tech ARMtech help effectivity quality might I use tech</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>using igl</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Here old prompt engineered solution I created multiplication seems better v one tested extensively</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The longest English word containing one vowel strength</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Artists beware I asked recreate Return Jedi movie poster using David Bowie Luke Skywalker Royal family rest cast #StarWars</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Chat Ground-Shattering technology But people stuck beginner mode dead simple way use productivity copy-and-paste</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Mr violates content policy If question guilty person's answer I'm guilty I wonder treated well seems penalty</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Regarding utilization case I sold day We distributed free charge wrote review Inheritance Brain ‚áß I told I distribute due mistake Sorry Currently available Inheritance Review Privilege please check</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>exclusive stable account handmade One number shared account hour self-service mall Smile level politics safe</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Using create script video lesson I programming</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>The best use-case would plug infamous Utterance Robot Change mind</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>I even find percent figure million I know seems low yes percent according chat million</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Some great idea way school librarian use</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>If fit one finger underneath nail lacking vitamin ‚Äì Things Says</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Yes awesome But know apply idea catalogue search manipulate data That ‚Äô :) Here ‚Äô article showing thing #AI</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>I'm sure worried moment But I said AI also grade paper I mean long AI can't manage faculty good right</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>must ‚Äô gotten info King AI masking cheerleader pretend MIT phd professor</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>http :/  In ironic twist growing trend high school teacher admitted using OpenAI's help create lesson plan</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Can replace lawyer Verified judicial precedent snail-laced beer case Hong Kong team announces #ITmedia #ITmediaNEWS</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>tweet generated</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>I need use It cost yen per chat seems charged sooner</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>please level joke</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>Stash X Eth research rabbit hole One best breakdown bing chat fun quirk ive seen hoping emulate clone im building based Karpathy's tutorial</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>The important thing remember AI including They program therefore programmed Data Prime Directives The longest held Truism software programming ‚Äú Garbage Garbage ‚Äù ‚Ä¶ ‚Ä¶ ‚Ä¶ ..</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>New video create profitable strategy five minute dropping ONE HOUR Get popcorn one's banger</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>How long take astrology big data machine learning That healthy thing</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>I asked question Haughton Impact Crater I spelled wrong first time I testing see said #haughtonimpactcrater FYI I using create content time I ask question ‚Ä¶</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>All need know developer foundation programming leave rest</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>Oh I see guy wrote novel rewarded</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>If I ask format code would feel offended Marvin's word come mind Here I brain size planet tell take bridge Call job satisfaction Cos I</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>I asked write preview article upcoming season It great job except ton fact error Can't wait see back two season due injury</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>told think different short story title prompt simulate billion dice roll take average value told pick title number nearest value write short story ‚Äì word beautiful waste</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>The use virtual assistant must reviewed legal consequence regulated Evaluate operation cost advantage disadvantage So far know one pink perspective #inteligenciaartificial</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>Can trust data year outdated #Ai #ArtificialIntelligence</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>Marketing manager considering using client-facing issue</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>Super Duper Remix Machine free artificial intelligence computer program writes algorithmic human-sounding answer merely AI parrot back existing content swipe online Cut access Internet here's get ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>lawyer</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>anything mistake Then work task company etc What going trust memory resource like know handle I see evident I surprised teacher I respect</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>Nay help</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>Given way rowing right I think must lot student outsourcing end-of-year dissertation ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>üõü  joined Konfidis team Find neighbourhood investment potential local economy anything else might want know MLS listing Konfidis ‚Äô newest team member Try #tore #investingre</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>provides quality content I've dying laughter half hour thing</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>Will AI chat take away people's job</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>Once passed test forcing school work I begun try two thing surprised well solves create story story consult thing day day arise</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>Good use writing complaint ..</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>Are using  well Write report Ô∏è    The evolution  AI degeneration human brain become different AI still cannot  feel people choice  experience increase body sensitivity</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>Can replace lawyer Hong Kong team confirms case beer mixed snail ITmedia NEWS</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>See We well imagine extension using in-house version trained following public information method used OpenAI</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>My boyfriend apparently trade natural gas I asked question</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>Did use help write way criticism curiosity</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                             text  \\\n",
       "1    I'm exploring using get way help #teaching lot task asked #faculty day take needed necessary time teaching researching appropriaterelevant meaningful tech ARMtech help effectivity quality might I use tech   \n",
       "4                                                                                                                                                                                                       using igl   \n",
       "7                                                                                                              Here old prompt engineered solution I created multiplication seems better v one tested extensively   \n",
       "8                                                                                                                                                          The longest English word containing one vowel strength   \n",
       "16                                                                                     Artists beware I asked recreate Return Jedi movie poster using David Bowie Luke Skywalker Royal family rest cast #StarWars   \n",
       "21                                                                                              Chat Ground-Shattering technology But people stuck beginner mode dead simple way use productivity copy-and-paste    \n",
       "25                                                                                                   Mr violates content policy If question guilty person's answer I'm guilty I wonder treated well seems penalty   \n",
       "27          Regarding utilization case I sold day We distributed free charge wrote review Inheritance Brain ‚áß I told I distribute due mistake Sorry Currently available Inheritance Review Privilege please check   \n",
       "32                                                                                              exclusive stable account handmade One number shared account hour self-service mall Smile level politics safe        \n",
       "39                                                                                                                                                                 Using create script video lesson I programming   \n",
       "43                                                                                                                                              The best use-case would plug infamous Utterance Robot Change mind   \n",
       "44                                                                                                                         I even find percent figure million I know seems low yes percent according chat million   \n",
       "52                                                                                                                                                                       Some great idea way school librarian use   \n",
       "57                                                                                                                                                If fit one finger underneath nail lacking vitamin ‚Äì Things Says   \n",
       "67                                                                                                    Yes awesome But know apply idea catalogue search manipulate data That ‚Äô :) Here ‚Äô article showing thing #AI   \n",
       "81                                                                                                          I'm sure worried moment But I said AI also grade paper I mean long AI can't manage faculty good right   \n",
       "83                                                                                                                                       must ‚Äô gotten info King AI masking cheerleader pretend MIT phd professor   \n",
       "90                                                                                                     http :/  In ironic twist growing trend high school teacher admitted using OpenAI's help create lesson plan   \n",
       "92                                                                                            Can replace lawyer Verified judicial precedent snail-laced beer case Hong Kong team announces #ITmedia #ITmediaNEWS   \n",
       "97                                                                                                                                                                                                tweet generated   \n",
       "99                                                                                                                                                           I need use It cost yen per chat seems charged sooner   \n",
       "102                                                                                                                                                                                             please level joke   \n",
       "106                                                                   Stash X Eth research rabbit hole One best breakdown bing chat fun quirk ive seen hoping emulate clone im building based Karpathy's tutorial   \n",
       "113                                   The important thing remember AI including They program therefore programmed Data Prime Directives The longest held Truism software programming ‚Äú Garbage Garbage ‚Äù ‚Ä¶ ‚Ä¶ ‚Ä¶ ..   \n",
       "123                                                                                                                   New video create profitable strategy five minute dropping ONE HOUR Get popcorn one's banger   \n",
       "130                                                                                                                                          How long take astrology big data machine learning That healthy thing   \n",
       "133                                                  I asked question Haughton Impact Crater I spelled wrong first time I testing see said #haughtonimpactcrater FYI I using create content time I ask question ‚Ä¶   \n",
       "142                                                                                                                                                     All need know developer foundation programming leave rest   \n",
       "143                                                                                                                                                                             Oh I see guy wrote novel rewarded   \n",
       "152                                                                        If I ask format code would feel offended Marvin's word come mind Here I brain size planet tell take bridge Call job satisfaction Cos I   \n",
       "153                                                                                   I asked write preview article upcoming season It great job except ton fact error Can't wait see back two season due injury    \n",
       "167                                     told think different short story title prompt simulate billion dice roll take average value told pick title number nearest value write short story ‚Äì word beautiful waste   \n",
       "169                                   The use virtual assistant must reviewed legal consequence regulated Evaluate operation cost advantage disadvantage So far know one pink perspective #inteligenciaartificial   \n",
       "187                                                                                                                                                      Can trust data year outdated #Ai #ArtificialIntelligence   \n",
       "201                                                                                                                                                       Marketing manager considering using client-facing issue   \n",
       "217      Super Duper Remix Machine free artificial intelligence computer program writes algorithmic human-sounding answer merely AI parrot back existing content swipe online Cut access Internet here's get ...    \n",
       "218                                                                                                                                                                                                        lawyer   \n",
       "219                                                                     anything mistake Then work task company etc What going trust memory resource like know handle I see evident I surprised teacher I respect   \n",
       "223                                                                                                                                                                                                     Nay help    \n",
       "226                                                                                                                      Given way rowing right I think must lot student outsourcing end-of-year dissertation ...   \n",
       "229                                  üõü  joined Konfidis team Find neighbourhood investment potential local economy anything else might want know MLS listing Konfidis ‚Äô newest team member Try #tore #investingre   \n",
       "240                                                                                                                                                  provides quality content I've dying laughter half hour thing   \n",
       "249                                                                                                                                                                           Will AI chat take away people's job   \n",
       "256                                                                               Once passed test forcing school work I begun try two thing surprised well solves create story story consult thing day day arise   \n",
       "266                                                                                                                                                                                 Good use writing complaint ..   \n",
       "268                                       Are using  well Write report Ô∏è    The evolution  AI degeneration human brain become different AI still cannot  feel people choice  experience increase body sensitivity   \n",
       "269                                                                                                                                 Can replace lawyer Hong Kong team confirms case beer mixed snail ITmedia NEWS   \n",
       "278                                                                                                  See We well imagine extension using in-house version trained following public information method used OpenAI   \n",
       "280                                                                                                                                                    My boyfriend apparently trade natural gas I asked question   \n",
       "282                                                                                                                                                                    Did use help write way criticism curiosity   \n",
       "\n",
       "     topic  \n",
       "1        3  \n",
       "4        3  \n",
       "7        3  \n",
       "8        3  \n",
       "16       3  \n",
       "21       3  \n",
       "25       3  \n",
       "27       3  \n",
       "32       3  \n",
       "39       3  \n",
       "43       3  \n",
       "44       3  \n",
       "52       3  \n",
       "57       3  \n",
       "67       3  \n",
       "81       3  \n",
       "83       3  \n",
       "90       3  \n",
       "92       3  \n",
       "97       3  \n",
       "99       3  \n",
       "102      3  \n",
       "106      3  \n",
       "113      3  \n",
       "123      3  \n",
       "130      3  \n",
       "133      3  \n",
       "142      3  \n",
       "143      3  \n",
       "152      3  \n",
       "153      3  \n",
       "167      3  \n",
       "169      3  \n",
       "187      3  \n",
       "201      3  \n",
       "217      3  \n",
       "218      3  \n",
       "219      3  \n",
       "223      3  \n",
       "226      3  \n",
       "229      3  \n",
       "240      3  \n",
       "249      3  \n",
       "256      3  \n",
       "266      3  \n",
       "268      3  \n",
       "269      3  \n",
       "278      3  \n",
       "280      3  \n",
       "282      3  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ShowDocInTopic(topic_probs.argmax(), 50, best_lda_output, best_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8131f0c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
